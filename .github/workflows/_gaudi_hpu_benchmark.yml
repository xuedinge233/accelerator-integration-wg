
name: '_gaudi_hpu_benchmark'

on:
  workflow_call:
    inputs:
      ref:
        required: false
        type: string
        default: 'refs/heads/main'
        description: 'The branch, tag or SHA to checkout'
      runner:
        required: true
        type: string
        description: 'The runner selected to run on'
      image:
        required: true
        type: string
        description: 'The docker image which will be loaded'
      device:
        required: true
        type: string
        description: 'The device selected to run on'
      torch-artifact:
        required: false
        type: string
        description: 'The distribution artifact name of torch'
      torch-hpu-artifact:
        required: true
        type: string
        description: 'The distribution artifact name of torch_hpu'
      torch-hpu-dl-artifact:
        required: true
        type: string
        description: 'The distribution artifact name of torch_hpu dataloader'
      python_version:
          required: false
          type: string
          default: '3.10'
          description: 'The python version to use'
      rel_ver:
        required: true
        type: string
        description: 'The release version of torch_hpu to use'

# Bash shells do not use ~/.profile or ~/.bashrc so these shells need to be explicitly
# declared as "shell: bash -el {0}" on steps that need to be properly activated.
# It's used to activate ascend-toolkit environment variables.
defaults:
  run:
    shell: bash -el {0}

jobs:
  test:
    name: run benchmarks for torch_hpu
    runs-on: ${{ inputs.runner }}
    container:
      image: ${{ inputs.image }}
      volumes:
        - /usr/local/dcmi:/usr/local/dcmi
        - /usr/local/bin/hl-smi:/usr/local/bin/hl-smi
      env:
        HABANA_VISIBLE_DEVICES: all
        OMPI_MCA_btl_vader_single_copy_mechanism: none
      options: >-
        --ipc host
        --cap-add sys_nice
        --runtime habana
    steps:
      - name: Show HPU info
        run: |
          hl-smi info

      - name: Setup Python environment
        uses: actions/setup-python@v5
        id: setup-python
        with:
          python-version: ${{ inputs.python_version }}
      - name: Setup CPATH
        run: |
          echo  "python version : ${{ steps.setup-python.outputs.python-version }}"
          python_version="${{ inputs.python_version }}"
          echo  "python path : ${{ steps.setup-python.outputs.python-path }}"
          CPATH=${pythonLocation}/include/python${python_version}
          echo CPATH=${CPATH} >> "${GITHUB_ENV}"

      # See: https://github.com/actions/checkout/issues/363#issuecomment-1915075699
      - name: Config git
        run: |
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

      - name: Checkout
        uses: actions/checkout@v4

      - name: Checkout PyTorch
        uses: actions/checkout@v4
        with:
          repository: pytorch/pytorch
          ref: ${{ inputs.ref }}
          submodules: recursive
          path: pytorch

      - name: Checkout torch_hpu
        uses: actions/checkout@v4
        with:
          repository: HabanaAI/gaudi-pytorch-bridge
          ref: v${{ inputs.rel_ver }}
          path: torch_hpu

      - name: Install pip dependencies
        working-directory: torch_hpu
        run: |
          pip install -r requirements.txt

      - name: Download torch artifact
        if: ${{ inputs.torch-artifact }}
        uses: actions/download-artifact@v5
        with:
          name: ${{ inputs.torch-artifact }}

      - name: Install torch
        if: ${{ inputs.torch-artifact }}
        run: |
          pip install ${{ inputs.torch-artifact }}

      - name: Download torch_hpu artifact
        uses: actions/download-artifact@v5
        with:
          # name: ${{ inputs.torch-hpu-artifact }}
          name: torch_hpu_dists
          path: torch_hpu

      - name: Install torch_hpu
        working-directory: torch_hpu
        run: |
          unzip torch_hpu_dists.zip && cd torch_hpu_dists
          pip install ${{ inputs.torch-hpu-artifact }}
          pip install ${{ inputs.torch-hpu-dl-artifact }}

      - name: List torch version
        id: list-torch-version
        shell: bash
        run: |
          torch_version=$(python -c "import torch; print(torch.__version__)")
          torch_git_version=$(python -c "import torch; print(torch.version.git_version)")
          # torchbench_version=$(curl https://raw.githubusercontent.com/pytorch/pytorch/${torch_git_version}/.github/ci_commit_pins/torchbench.txt)
          torchbench_version=main
          torchvision_version=$(curl https://raw.githubusercontent.com/pytorch/pytorch/${torch_git_version}/.github/ci_commit_pins/vision.txt)
          torchaudio_version=$(curl https://raw.githubusercontent.com/pytorch/pytorch/${torch_git_version}/.github/ci_commit_pins/audio.txt)
          hf_version=$(curl https://raw.githubusercontent.com/pytorch/pytorch/${torch_git_version}/.ci/docker/ci_commit_pins/huggingface.txt)
          echo "torch-version=${torch_version}" >> $GITHUB_OUTPUT
          echo "torch-git-version=${torch_git_version}" >> $GITHUB_OUTPUT
          echo "torchbench-version=${torchbench_version}" >> $GITHUB_OUTPUT
          echo "torchvision-version=${torchvision_version}" >> $GITHUB_OUTPUT
          echo "torchaudio-version=${torchaudio_version}" >> $GITHUB_OUTPUT
          echo "hf-version=${hf_version}" >> $GITHUB_OUTPUT

      - name: Show environment info
        run: |
          export PT_HPU_LAZY_MODE=0
          hpu_is_available=$(python -c "import torch; print(torch.hpu.is_available())")
          hpu_count=$(python -c "import torch; print(torch.hpu.device_count())")
          echo "HPU is available: ${hpu_is_available}"
          echo "HPU count: ${hpu_count}"
          pip list | grep -E 'torch|numpy'

      - name: Checkout benchmark
        uses: actions/checkout@v4
        with:
          repository: pytorch/benchmark
          ref: ${{ steps.list-torch-version.outputs.torchbench-version }}
          path: benchmark

      - name: Checkout vision
        uses: actions/checkout@v4
        with:
          repository: pytorch/vision
          ref: ${{ steps.list-torch-version.outputs.torchvision-version }}
          path: vision

      - name: Checkout audio
        uses: actions/checkout@v4
        with:
          repository: pytorch/audio
          ref: ${{ steps.list-torch-version.outputs.torchaudio-version }}
          path: audio
          
      - name: Install torchvision torchaudio and transfoermers
        run: |
          cd vision && python setup.py bdist_wheel && pip uninstall torchvision -y && pip install dist/*.whl && cd ..
          cd audio && python setup.py bdist_wheel && pip uninstall torchaudio -y && pip install dist/*.whl && cd ..
          pip install --force-reinstall git+https://github.com/huggingface/transformers@${{ steps.list-torch-version.outputs.hf-version }}
  
      - name: Install benchmark dependencies
        run: |
          pip install -r benchmark/requirements.txt

      - name: Install dependencies for all the models
        run: |
          python benchmark/install.py --userbenchmark test_bench --continue_on_fail
      
      - name: Install project dependencies
        run: |
          pip install -r requirements.txt

      - name: Show environment info
        run: |
          export PT_HPU_LAZY_MODE=0
          hpu_is_available=$(python -c "import torch; print(torch.hpu.is_available())")
          hpu_count=$(python -c "import torch; print(torch.hpu.device_count())")
          echo "HPU is available: ${hpu_is_available}"
          echo "HPU count: ${hpu_count}"
          pip list | grep -E 'torch|numpy'

      - name: Run benchmarks
        working-directory: benchmark
        run: |
          export PT_HPU_LAZY_MODE=0
          echo "Run torchbench"
          python run_benchmark.py test_bench --accuracy --device hpu --test eval \
               --output gaudi_hpu_benchmark.json

      - name: Upload the benchmark report file
        id: upload-report
        uses: actions/upload-artifact@v4
        with:
          name: gaudi_hpu_benchmark.json
          path: benchmark/gaudi_hpu_benchmark.json
          if-no-files-found: error
          retention-days: 1
          overwrite: true

      - name: Write to workflow job summary
        run: |
          echo "Write to workflow job summary"
          python .ci/benchmark.py --write-gh-job-summary --path benchmark/gaudi_hpu_benchmark.json

      - name: Write to workflow job summary
        run: |
          echo "TODO: update test results dashboard"
    
      - name: Cleanup workspace
        if: always()
        run: rm -rf ${{ github.workspace }}/*
